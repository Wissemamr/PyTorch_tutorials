{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.0 : Tensors...the basic building blocks of ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\pc caba dz\\appdata\\roaming\\python\\python310\\site-packages (2.1.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\pc caba dz\\appdata\\roaming\\python\\python310\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: fsspec in c:\\users\\pc caba dz\\appdata\\roaming\\python\\python310\\site-packages (from torch) (2023.12.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pc caba dz\\appdata\\roaming\\python\\python310\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\pc caba dz\\appdata\\roaming\\python\\python310\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\pc caba dz\\appdata\\roaming\\python\\python310\\site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\pc caba dz\\appdata\\roaming\\python\\python310\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pc caba dz\\appdata\\roaming\\python\\python310\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\pc caba dz\\appdata\\roaming\\python\\python310\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors are the fundamental building block of machine learning.\n",
    "\n",
    "Their job is to represent data in a numerical way.\n",
    "\n",
    "For example, you could represent an image as a tensor with shape [3, 224, 224] which would mean [colour_channels, height, width], as in the image has 3 colour channels (red, green, blue), a height of 224 pixels and a width of 224 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = torch.tensor(5)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(scalar.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn the sdcalar into an int, works just with one value tensors\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 9, 4])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = torch.tensor([8, 9, 4])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(vector.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [8, 5, 3]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = torch.tensor([[1, 2, 3], [8, 5, 3]])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(matrix.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "matrix2 = torch.tensor([[[3, 5, 6], [5, 9, 1], [0, 2, 6]]])\n",
    "print(matrix2.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.tensor() always copies data. If you have a Tensor data and just want to change its requires_grad flag, use requires_grad_() or detach() to avoid a copy. If you have a numpy array and want to avoid a copy, use torch.as_tensor()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([4, 7, 8], requires_grad=False)\n",
    "print(tensor.is_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 6, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([0, 6, 3, 4]).detach()\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 6, 8, 7], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "np_arr = np.array([4, 6, 8, 7])\n",
    "arr_to_tens = torch.as_tensor(np_arr)\n",
    "print(arr_to_tens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 5., 6., 7., 4.])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu = torch.device(\"cpu\")\n",
    "tens = torch.tensor([0, 5, 6, 7, 4], dtype=torch.float32, device=cpu)\n",
    "tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1], dtype=torch.int32)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones(5, dtype=torch.int32)\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros(6)\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 7, 8, 3, 2],\n",
      "        [4, 6, 7, 8, 7],\n",
      "        [6, 8, 2, 1, 3]])\n",
      "tensor(8)\n",
      "tensor([5, 4, 6])\n"
     ]
    }
   ],
   "source": [
    "test_tens = torch.tensor([[5, 7, 8, 3, 2], [4, 6, 7, 8, 7], [6, 8, 2, 1, 3]])\n",
    "print(test_tens)\n",
    "print(test_tens[0][2])\n",
    "print(test_tens[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tensor can be created with requires_grad=True so that torch.autograd records operations on them for automatic differentiation.\n",
    "<br>\n",
    "A tensor can be created with requires_grad=True so that torch.autograd records operations on them for automatic differentiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9., 5., 4., 3., 0.], dtype=torch.float64, requires_grad=True)\n",
      "tensor([18., 10.,  8.,  6.,  0.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "grad_tens = torch.tensor([9, 5, 4, 3, 0], dtype=torch.float64, requires_grad=True)\n",
    "print(grad_tens)\n",
    "opt = grad_tens.pow(2).sum()\n",
    "opt.backward()\n",
    "print(grad_tens.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods which mutate a tensor are marked with an underscore suffix. For example, torch.FloatTensor.abs_() computes the absolute value in-place and returns the modified tensor, while torch.FloatTensor.abs() computes the result in a new tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To change an existing tensor’s torch.device and/or torch.dtype, consider using to() method on the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "tenss = torch.tensor([5, 6, 4, 3])\n",
    "print(tenss.dtype)\n",
    "# tenss = tenss.to(torch.float64)\n",
    "# print(tenss.dtype)\n",
    "print(tenss.float().dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(tenss.is_cuda)\n",
    "print(tenss.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But when building machine learning models with PyTorch, it's rare you'll create tensors by hand (like what we've being doing).\n",
    "\n",
    "Instead, a machine learning model often starts out with large random tensors of numbers and adjusts these random numbers as it works through data to better represent it.\n",
    "\n",
    "In essence:\n",
    "\n",
    "Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2666, 0.6274, 0.2696, 0.4414, 0.2969, 0.8317, 0.1053],\n",
      "        [0.2695, 0.3588, 0.1994, 0.5472, 0.0062, 0.9516, 0.0753],\n",
      "        [0.8860, 0.5832, 0.3376, 0.8090, 0.5779, 0.9040, 0.5547],\n",
      "        [0.3423, 0.6343, 0.3644, 0.7104, 0.9464, 0.7890, 0.2814],\n",
      "        [0.7886, 0.5895, 0.7539, 0.1952, 0.0050, 0.3068, 0.1165]])\n"
     ]
    }
   ],
   "source": [
    "random_tensor = torch.rand((5, 7))\n",
    "print(random_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  3,  5,  7,  9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35,\n",
      "        37, 39, 41, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 63, 65, 67, 69, 71,\n",
      "        73, 75, 77, 79, 81, 83, 85, 87, 89, 91, 93, 95, 97, 99])\n"
     ]
    }
   ],
   "source": [
    "# torch.arange(start, end, step)\n",
    "rang_tens = torch.arange(1, 100, 2)\n",
    "print(rang_tens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common issues \n",
    "Aside from shape issues (tensor shapes don't match up), two of the other most common issues you'll come across in PyTorch are datatype and device issues.\n",
    "\n",
    "For example, one of tensors is torch.float32 and the other is torch.float16 (PyTorch often likes tensors to be the same format).\n",
    "\n",
    "Or one of your tensors is on the CPU and the other is on the GPU (PyTorch likes calculations between tensors to be on the same device).\n",
    "\n",
    "Note: When you run into issues in PyTorch, it's very often one to do with one of the three attributes above. So when the error messages show up, sing yourself a little song called \"what, what, where\":\n",
    "\n",
    "\"what shape are my tensors? what datatype are they and where are they stored? what shape, what datatype, where where where\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating tensors (tensor operations)¶\n",
    "In deep learning, data (images, text, video, audio, protein structures, etc) gets represented as tensors.\n",
    "\n",
    "A model learns by investigating those tensors and performing a series of operations (could be 1,000,000s+) on tensors to create a representation of the patterns in the input data.\n",
    "\n",
    "These operations are often a wonderful dance between:\n",
    "\n",
    "- Addition\n",
    "- Substraction\n",
    "- Multiplication (element-wise)\n",
    "- Division\n",
    "- Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING @ OPERATOR : \n",
      "tensor([[0.9313, 0.7367, 1.3473, 1.3242],\n",
      "        [0.7607, 0.8019, 1.2323, 1.3081],\n",
      "        [0.5766, 0.1871, 0.2474, 0.2996],\n",
      "        [0.5605, 0.6195, 1.0662, 1.0697],\n",
      "        [1.0106, 0.3028, 0.5179, 0.5498]])\n",
      "\n",
      "USING MATMUL : \n",
      " tensor([[0.9313, 0.7367, 1.3473, 1.3242],\n",
      "        [0.7607, 0.8019, 1.2323, 1.3081],\n",
      "        [0.5766, 0.1871, 0.2474, 0.2996],\n",
      "        [0.5605, 0.6195, 1.0662, 1.0697],\n",
      "        [1.0106, 0.3028, 0.5179, 0.5498]])\n",
      "\n",
      "USING MM : \n",
      " tensor([[0.9313, 0.7367, 1.3473, 1.3242],\n",
      "        [0.7607, 0.8019, 1.2323, 1.3081],\n",
      "        [0.5766, 0.1871, 0.2474, 0.2996],\n",
      "        [0.5605, 0.6195, 1.0662, 1.0697],\n",
      "        [1.0106, 0.3028, 0.5179, 0.5498]])\n"
     ]
    }
   ],
   "source": [
    "# matrix multiplication aka dot product\n",
    "\n",
    "tensor1 = torch.rand((5, 3))\n",
    "tensor2 = torch.rand((3, 4))\n",
    "\n",
    "\n",
    "# we can use @ but it's not recommended\n",
    "print(f\"USING @ OPERATOR : \\n{tensor1 @ tensor2}\")\n",
    "print(f\"\\nUSING MATMUL : \\n {torch.matmul(tensor1, tensor2)}\")\n",
    "print(f\"\\nUSING MM : \\n {torch.mm(tensor1, tensor2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The torch.nn.Linear() module (we'll see this in action later on), also known as a feed-forward layer or fully connected layer, implements a matrix multiplication between an input x and a weights matrix A\n",
    "\n",
    "\n",
    "$$  y = x.W^T + b $$\n",
    "\n",
    "- x is the input to the layer (deep learning is a stack of layers like torch.nn.Linear() and others on top of each other).\n",
    "- W is the weights matrix created by the layer, this starts out as random numbers that get adjusted as a neural network learns to better represent patterns in the data (notice the \"T\", that's because the weights matrix gets transposed).\n",
    "\n",
    "- b is the bias term used to slightly offset the weights and inputs.\n",
    "- y is the output (a manipulation of the input in the hopes to discover patterns in it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([3, 2])\n",
      "\n",
      "Output:\n",
      "tensor([[2.2368, 1.2292, 0.4714, 0.3864, 0.1309, 0.9838],\n",
      "        [4.4919, 2.1970, 0.4469, 0.5285, 0.3401, 2.4777],\n",
      "        [6.7469, 3.1648, 0.4224, 0.6705, 0.5493, 3.9716]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Output shape: torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "# Since the linear layer starts with a random weights matrix, let's make it reproducible\n",
    "torch.manual_seed(42)\n",
    "# This uses matrix multiplication\n",
    "linear = torch.nn.Linear(\n",
    "    in_features=2, out_features=6  # in_features = matches inner dimension of input\n",
    ")  # out_features = describes outer value\n",
    "\n",
    "tensor_A = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "# mat mul ( in_feature = 2 cuz = (3,2) out_feature = 6 cuz (2,6) )\n",
    "x = tensor_A\n",
    "output = linear(x)\n",
    "print(f\"Input shape: {x.shape}\\n\")\n",
    "print(f\"Output:\\n{output}\\n\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating tensors\n",
    "\n",
    "Finding the min, max, mean, sum, etc (aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000,\n",
       "        0.9000, 1.0000, 1.1000, 1.2000, 1.3000, 1.4000, 1.5000, 1.6000, 1.7000,\n",
       "        1.8000, 1.9000, 2.0000, 2.1000, 2.2000, 2.3000, 2.4000, 2.5000, 2.6000,\n",
       "        2.7000, 2.8000, 2.9000, 3.0000, 3.1000, 3.2000, 3.3000, 3.4000, 3.5000,\n",
       "        3.6000, 3.7000, 3.8000, 3.9000, 4.0000, 4.1000, 4.2000, 4.3000, 4.4000,\n",
       "        4.5000, 4.6000, 4.7000, 4.8000, 4.9000])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(0, 5, 0.1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE MAX : 4.900000095367432\n",
      "THE INDEX OF THE MAX : 49\n",
      "THE MIN : 0.0\n",
      "THE INDEX OF THE MIN : 0\n",
      "THE SUM : 122.49999237060547\n",
      "THE MEAN : 2.4499998092651367\n",
      "THE STD : 1.457737922668457\n"
     ]
    }
   ],
   "source": [
    "print(f\"THE MAX : { torch.max(x)}\")  # or x.mean() ...\n",
    "print(f\"THE INDEX OF THE MAX : {torch.argmax(x)}\")\n",
    "print(f\"THE MIN : {torch.min(x)}\")\n",
    "print(f\"THE INDEX OF THE MIN : {torch.argmin(x)}\")\n",
    "print(f\"THE SUM : {torch.sum(x)}\")\n",
    "print(f\"THE MEAN : {torch.mean(x)}\")\n",
    "print(f\"THE STD : {torch.std(x)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Reshaping, stacking, squeezing and unsqueezing\n",
    "\n",
    "\n",
    "Because deep learning models (neural networks) are all about manipulating tensors in some way. And because of the rules of matrix multiplication, if you've got shape mismatches, you'll run into errors. These methods help you make sure the right elements of your tensors are mixing with the right elements of other tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.arange(1, 10)\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
      "torch.Size([1, 9])\n"
     ]
    }
   ],
   "source": [
    "reshaped_tensor = tensor.reshape(1, 9)  # 9 puisque l'ancienne dim was 9\n",
    "print(reshaped_tensor)\n",
    "print(reshaped_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9]]), tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]))"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = tensor.view(1, 9)  # changing the view changes the original tensor too.\n",
    "z, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "         [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "         [1, 2, 3, 4, 5, 6, 7, 8, 9]]),\n",
       " torch.Size([3, 9]))"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_tens = torch.stack([tensor, tensor, tensor], dim=0)\n",
    "stacked_tens, stacked_tens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 1, 1],\n",
       "         [2, 2, 2],\n",
       "         [3, 3, 3],\n",
       "         [4, 4, 4],\n",
       "         [5, 5, 5],\n",
       "         [6, 6, 6],\n",
       "         [7, 7, 7],\n",
       "         [8, 8, 8],\n",
       "         [9, 9, 9]]),\n",
       " torch.Size([9, 3]))"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_tens = torch.stack([tensor, tensor, tensor], dim=1)\n",
    "stacked_tens, stacked_tens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
      "Previous shape: torch.Size([1, 9])\n",
      "\n",
      "New tensor: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "New shape: torch.Size([9])\n",
      "\n",
      "New tensor: tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
      "New shape: torch.Size([1, 9])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Previous tensor: {reshaped_tensor}\")\n",
    "print(f\"Previous shape: {reshaped_tensor.shape}\")\n",
    "\n",
    "# Remove extra dimension from reshaped_tensor\n",
    "x_squeezed = reshaped_tensor.squeeze()\n",
    "print(f\"\\nNew tensor: {x_squeezed}\")\n",
    "print(f\"New shape: {x_squeezed.shape}\")\n",
    "\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
    "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
    "print(f\"New shape: {x_unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([224, 224, 3])\n",
      "New shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Create tensor with specific shape\n",
    "x_original = torch.rand(size=(224, 224, 3))\n",
    "\n",
    "# Permute the original tensor to rearrange the axis order\n",
    "x_permuted = x_original.permute(2, 0, 1)  # shifts axis 0->1, 1->2, 2->0\n",
    "\n",
    "print(f\"Previous shape: {x_original.shape}\")\n",
    "print(f\"New shape: {x_permuted.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Indexing and slicing \n",
    "\n",
    "Indexing values goes outer dimension -> inner dimension (check out the square brackets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First square bracket:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "Second square bracket: tensor([1, 2, 3])\n",
      "Third square bracket: 1\n"
     ]
    }
   ],
   "source": [
    "# Let's index bracket by bracket\n",
    "print(f\"First square bracket:\\n{x[0]}\")\n",
    "print(f\"Second square bracket: {x[0][0]}\")\n",
    "print(f\"Third square bracket: {x[0][0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch tensors & NumPy\n",
    "\n",
    "The two main methods you'll want to use for NumPy to PyTorch (and back again) are:\n",
    "\n",
    "torch.from_numpy(ndarray) - NumPy array -> PyTorch tensor.\n",
    "\n",
    "torch.Tensor.numpy() - PyTorch tensor -> NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3, 6, 7],\n",
       "         [0, 7, 1]], dtype=torch.int32),\n",
       " torch.Tensor)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([[3, 6, 7], [0, 7, 1]])\n",
    "tens = torch.from_numpy(arr)\n",
    "tens, type(tens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[5, 7, 1],\n",
       "        [0, 5, 3],\n",
       "        [4, 5, 3]], dtype=int64),\n",
       " numpy.ndarray)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([[5, 7, 1], [0, 5, 3], [4, 5, 3]])\n",
    "nd_array = tensor.numpy()\n",
    "nd_array, type(nd_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducibility (trying to take the random out of random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor C:\n",
      "tensor([[0.4540, 0.1965, 0.9210, 0.3462],\n",
      "        [0.1481, 0.0858, 0.5909, 0.0659],\n",
      "        [0.7476, 0.6253, 0.9392, 0.1338]])\n",
      "\n",
      "Tensor D:\n",
      "tensor([[0.4540, 0.1965, 0.9210, 0.3462],\n",
      "        [0.1481, 0.0858, 0.5909, 0.0659],\n",
      "        [0.7476, 0.6253, 0.9392, 0.1338]])\n",
      "\n",
      "Does Tensor C equal Tensor D? (anywhere)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "#  Set the random seed\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(seed=RANDOM_SEED)\n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "torch.random.manual_seed(\n",
    "    seed=RANDOM_SEED\n",
    ")  # try commenting this line out and seeing what happens\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Tensor C:\\n{random_tensor_C}\\n\")\n",
    "print(f\"Tensor D:\\n{random_tensor_D}\\n\")\n",
    "print(f\"Does Tensor C equal Tensor D? (anywhere)\")\n",
    "random_tensor_C == random_tensor_D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running tensors on GPUs (and making faster computations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: When I reference \"GPU\" throughout this course, I'm referencing a Nvidia GPU with CUDA enabled (CUDA is a computing platform and API that helps allow GPUs be used for general purpose computing & not just graphics) unless otherwise specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme ex�cutable ou un fichier de commandes.\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to know if cuda is available and Pytorch has access to GPU\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to know how many GPUS we have\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE : \n",
    "Make sure to write <b>  device agnostic code </b> wich means code that'll run on CPU (always available) or GPU (if available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device type\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE :\n",
    "Putting a tensor on GPU using to(device) (e.g. some_tensor.to(device)) returns a copy of that tensor, e.g. the same tensor will be on CPU and GPU. To overwrite tensors, reassign them:\n",
    "\n",
    "some_tensor = some_tensor.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving tensors back to the CPU \n",
    "\n",
    "For example, you'll want to do this if you want to interact with your tensors with NumPy (NumPy does not leverage the GPU).\n",
    "\n",
    "This copies the tensor to CPU memory so it's usable with CPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.27611536, 0.83956444, 0.15627259, 0.10720509, 0.72614056],\n",
       "       dtype=float32),\n",
       " numpy.ndarray)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instead, copy the tensor back to cpu\n",
    "tensor_on_gpu = torch.rand(5)\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu, type(tensor_back_on_cpu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
